{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6854b2d8528a4c2ba348fcf349142c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheng\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sheng\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b86005584b475ea9350e48c2468760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13761fed024a4893ac079716768ea469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8108b4b9a612436c8f1e3e3a151078c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e65ba85fa545bc917b6c513284ef31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e489ab5eac54d789d5a71e875bafe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02d88fa15bb4940b4bb6af864593329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2704abffa104dd3b284b5fb5e537f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fafbba6b474022aecc2f05703e7bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/54.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForMaskedLM were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['electra.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import string\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased').eval()\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large').eval()\n",
    "\n",
    "from transformers import ElectraTokenizer, ElectraForMaskedLM\n",
    "electra_tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-generator')\n",
    "electra_model = ElectraForMaskedLM.from_pretrained('google/electra-small-generator').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "\n",
    "def decode(tokenizer, pred_idx, top_clean):\n",
    "    ignore_tokens = string.punctuation + '[PAD]'\n",
    "    tokens = []\n",
    "    for w in pred_idx:\n",
    "        token = ''.join(tokenizer.decode(w).split())\n",
    "        if token not in ignore_tokens:\n",
    "            tokens.append(token.replace('##', ''))\n",
    "    return '\\n'.join(tokens[:top_clean])\n",
    "\n",
    "\n",
    "def encode(tokenizer, text_sentence, add_special_tokens=True):\n",
    "    text_sentence = text_sentence.replace('<mask>', tokenizer.mask_token)\n",
    "    # if <mask> is the last token, append a \".\" so that models dont predict punctuation.\n",
    "    if tokenizer.mask_token == text_sentence.split()[-1]:\n",
    "        text_sentence += ' .'\n",
    "\n",
    "    input_ids = torch.tensor([tokenizer.encode(text_sentence, add_special_tokens=add_special_tokens)])\n",
    "    mask_idx = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n",
    "    return input_ids, mask_idx\n",
    "\n",
    "\n",
    "def get_predictions(text_sentence, top_clean=5):\n",
    "    # ========================= BERT =================================\n",
    "    print(text_sentence)\n",
    "    input_ids, mask_idx = encode(bert_tokenizer, text_sentence)\n",
    "    with torch.no_grad():\n",
    "        predict = bert_model(input_ids)[0]\n",
    "    bert = decode(bert_tokenizer, predict[0, mask_idx, :].topk(top_k).indices.tolist(), top_clean)\n",
    "    \n",
    "    input_ids, mask_idx = encode(bart_tokenizer, text_sentence, add_special_tokens=True)\n",
    "    with torch.no_grad():\n",
    "        predict = bart_model(input_ids)[0]\n",
    "    bart = decode(bart_tokenizer, predict[0, mask_idx, :].topk(top_k).indices.tolist(), top_clean)\n",
    "    \n",
    "    input_ids, mask_idx = encode(electra_tokenizer, text_sentence, add_special_tokens=True)\n",
    "    with torch.no_grad():\n",
    "        predict = electra_model(input_ids)[0]\n",
    "    electra = decode(electra_tokenizer, predict[0, mask_idx, :].topk(top_k).indices.tolist(), top_clean)\n",
    "\n",
    "    return {'bert': bert,\"bart\":bart,\"electra\":electra}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are <mask>\n"
     ]
    }
   ],
   "source": [
    "input_text=\"Hello, how are\"\n",
    "input_text += ' <mask>'\n",
    "res = get_predictions(input_text, top_clean=int(top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'ya', 'we', 'things', 'ye']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"bert\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'things', 'ya', 'we', 'y']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"bart\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'we', 'they', 'i', 'these']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"electra\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  39\n",
      "Word: ID\n",
      "------------\n",
      "<oov>:  1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'strong'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\Next_word_prediction_2023\\transformer_test.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m<oov>: \u001b[39m\u001b[39m\"\u001b[39m, tokenizer\u001b[39m.\u001b[39mword_index[\u001b[39m'\u001b[39m\u001b[39m<oov>\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStrong: \u001b[39m\u001b[39m\"\u001b[39m, tokenizer\u001b[39m.\u001b[39;49mword_index[\u001b[39m'\u001b[39;49m\u001b[39mstrong\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAnd: \u001b[39m\u001b[39m\"\u001b[39m, tokenizer\u001b[39m.\u001b[39mword_index[\u001b[39m'\u001b[39m\u001b[39mand\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConsumption: \u001b[39m\u001b[39m\"\u001b[39m, tokenizer\u001b[39m.\u001b[39mword_index[\u001b[39m'\u001b[39m\u001b[39mconsumption\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'strong'"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='<oov>') # For those words which are not found in word_index\n",
    "tokenizer.fit_on_texts(text)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Total number of words: \", total_words)\n",
    "print(\"Word: ID\")\n",
    "print(\"------------\")\n",
    "print(\"<oov>: \", tokenizer.word_index['<oov>'])\n",
    "print(\"Strong: \", tokenizer.word_index['strong'])\n",
    "print(\"And: \", tokenizer.word_index['and'])\n",
    "print(\"Consumption: \", tokenizer.word_index['consumption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sheng\\Documents\\GitHub\\Next_word_prediction_2023\\transformer_test.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         n_gram_sequence \u001b[39m=\u001b[39m token_list[:i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         input_sequences\u001b[39m.\u001b[39mappend(n_gram_sequence)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m max_sequence_len \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m([\u001b[39mlen\u001b[39;49m(x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m input_sequences])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m input_sequences \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(pad_sequences(input_sequences, maxlen\u001b[39m=\u001b[39mmax_sequence_len, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpre\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sheng/Documents/GitHub/Next_word_prediction_2023/transformer_test.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m input_sequences[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "input_sequences = []\n",
    "for line in text:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    #print(token_list)\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'fairest', 'creatures', 'we', 'desire']\n",
      "increase\n"
     ]
    }
   ],
   "source": [
    "unique_words = np.unique(words)\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
    "\n",
    "WORD_LENGTH = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(len(words) - WORD_LENGTH):\n",
    "    prev_words.append(words[i:i + WORD_LENGTH])\n",
    "    next_words.append(words[i + WORD_LENGTH])\n",
    "print(prev_words[0])\n",
    "print(next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
    "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
    "for i, each_words in enumerate(prev_words):\n",
    "    for j, each_word in enumerate(each_words):\n",
    "        X[i, j, unique_word_index[each_word]] = 1\n",
    "    Y[i, unique_word_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheng\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1388/1388 [==============================] - 247s 177ms/step - loss: 6.3676 - accuracy: 0.0827 - val_loss: 6.7137 - val_accuracy: 0.1066\n",
      "Epoch 2/10\n",
      "1388/1388 [==============================] - 233s 168ms/step - loss: 6.4258 - accuracy: 0.1175 - val_loss: 7.0606 - val_accuracy: 0.1082\n",
      "Epoch 3/10\n",
      "1388/1388 [==============================] - 238s 171ms/step - loss: 6.2068 - accuracy: 0.1366 - val_loss: 7.2836 - val_accuracy: 0.1075\n",
      "Epoch 4/10\n",
      "1388/1388 [==============================] - 238s 171ms/step - loss: 5.7105 - accuracy: 0.1656 - val_loss: 7.5751 - val_accuracy: 0.0954\n",
      "Epoch 5/10\n",
      "1388/1388 [==============================] - 232s 167ms/step - loss: 5.1736 - accuracy: 0.2033 - val_loss: 7.7755 - val_accuracy: 0.0860\n",
      "Epoch 6/10\n",
      "1388/1388 [==============================] - 230s 166ms/step - loss: 4.6548 - accuracy: 0.2476 - val_loss: 8.2830 - val_accuracy: 0.0790\n",
      "Epoch 7/10\n",
      "1388/1388 [==============================] - 229s 165ms/step - loss: 4.2101 - accuracy: 0.2921 - val_loss: 8.6616 - val_accuracy: 0.0733\n",
      "Epoch 8/10\n",
      "1388/1388 [==============================] - 233s 168ms/step - loss: 3.8425 - accuracy: 0.3334 - val_loss: 8.8182 - val_accuracy: 0.0666\n",
      "Epoch 9/10\n",
      "1388/1388 [==============================] - 233s 168ms/step - loss: 3.5349 - accuracy: 0.3736 - val_loss: 9.0821 - val_accuracy: 0.0663\n",
      "Epoch 10/10\n",
      "1388/1388 [==============================] - 236s 170ms/step - loss: 3.2799 - accuracy: 0.4068 - val_loss: 9.4656 - val_accuracy: 0.0664\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
    "model.add(Dense(len(unique_words)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=10, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
